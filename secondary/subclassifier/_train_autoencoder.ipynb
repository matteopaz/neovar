{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autoencoder import *\n",
    "from varnet import VARnet\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, clear_output\n",
    "from dataloader import Trainer\n",
    "\n",
    "# torch.multiprocessing.set_start_method('spawn')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_parquet('/home/mpaz/neovar/secondary/data/training_data.parquet')\n",
    "training_data = training_data[training_data[\"type\"] != \"rscvn\"]\n",
    "print(len(training_data))\n",
    "print(training_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traind = []\n",
    "validd = []\n",
    "for type_ in training_data['type'].unique():\n",
    "    indices = training_data['type'] == type_\n",
    "    oftype = training_data[indices]\n",
    "    traind.append(oftype.sample(frac=0.9))\n",
    "    validd.append(oftype.drop(traind[-1].index))\n",
    "\n",
    "traind = pd.concat(traind)\n",
    "validd = pd.concat(validd)\n",
    "\n",
    "print(training_data.value_counts('type'))\n",
    "print(traind.value_counts('type'))\n",
    "print(validd.value_counts('type'))\n",
    "\n",
    "# trainer = Trainer(traind, 64, 4096, False, True, multithread=True, bin_overlap_frac=0.25)\n",
    "# print(len(trainer))\n",
    "valid = Trainer(validd, 64, 4096, False, True, multithread=True, bin_overlap_frac=0.25)\n",
    "print(len(valid))\n",
    "\n",
    "print(torch.sum(torch.isnan(trainer.tensor)))\n",
    "print(torch.sum(torch.isinf(trainer.tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"trainer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trainer, f)\n",
    "with open(\"valid.pkl\", \"wb\") as f:\n",
    "    pickle.dump(valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"trainer.pkl\", \"rb\") as f:\n",
    "    trainer = pickle.load(f)\n",
    "with open(\"valid.pkl\", \"rb\") as f:\n",
    "    valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "bins = 64\n",
    "# model = VARnet(128, len(trainer.types), learnsamples=False, wavelet=\"haar\", infeatures=2)\n",
    "model = Morphologic(bins, len(trainer.types), 2)\n",
    "model.load_state_dict(torch.load(\"model/morpho.pth\"))\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "epochs = 1500\n",
    "loss = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00015, weight_decay=10**-6)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0015, weight_decay=10**-6)\n",
    "\n",
    "losses = []\n",
    "validlosses = []\n",
    "f1s = []\n",
    "model.train()\n",
    "iterlim = 50\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    epochlosses = []\n",
    "    validations = []\n",
    "    i=0\n",
    "    for data, target in trainer:\n",
    "        if i > iterlim:\n",
    "            break\n",
    "        i += 1\n",
    "        out = model(data.cuda())\n",
    "        if torch.sum(torch.isinf(out)) > 0:\n",
    "            print(out)\n",
    "            raise ValueError(\"NaN in output\")\n",
    "        if torch.sum(torch.isinf(data)) > 0:\n",
    "            print(data)\n",
    "            raise ValueError(\"NaN in input\")\n",
    "        if torch.sum(torch.isinf(target)) > 0:\n",
    "            print(target)\n",
    "            raise ValueError(\"NaN in target\")\n",
    "\n",
    "        l = loss(out, target.cuda())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epochlosses.append(l.item())\n",
    "    \n",
    "\n",
    "    # print a confusion matrix\n",
    "    epoch_validlosses = []\n",
    "    model.eval()\n",
    "    for data, target in valid:\n",
    "        out = model(data.cuda())\n",
    "        epochlosses.append(loss(out, target.cuda()).item())\n",
    "        pred = torch.argmax(out, dim=1).squeeze()\n",
    "        target = torch.argmax(target, dim=1).squeeze()\n",
    "        validations.append((target.cpu(), pred.cpu()))\n",
    "        epoch_validlosses.append((target.cpu(), pred.cpu()))\n",
    "    \n",
    "    validlosses.append(np.mean(epoch_validlosses))\n",
    "    true_y = torch.cat([x[0] for x in validations]).cpu().numpy()\n",
    "    pred_y = torch.cat([x[1] for x in validations]).cpu().numpy()\n",
    "    print(\"N Valids: \", len(true_y))\n",
    "    f1 = f1_score(true_y, pred_y, average=\"macro\")\n",
    "    f1s.append(f1)\n",
    "    cm = confusion_matrix(true_y, pred_y)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"])\n",
    "    losses.append(np.mean(epochlosses))\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=losses, line=dict(color=\"blue\"), mode=\"lines\", name=\"train\"))\n",
    "    fig.add_trace(go.Scatter(y=f1s, line=dict(color=\"red\"), mode=\"lines\", name=\"f1\"))\n",
    "    # fig.add_trace(go.Scatter(y=validlosses, line=dict(color=\"orange\"), mode=\"lines\", name=\"valid\"))\n",
    "\n",
    "    if e % 1 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Epoch {e} loss: {np.mean(epochlosses)}\")\n",
    "        print(f\"Epoch {e} valid loss: {np.mean(epoch_validlosses)}\")\n",
    "        print(f\"Epoch {e} f1: {f1}\")\n",
    "        display(fig)\n",
    "        print(confusion_matrix(true_y, pred_y))\n",
    "    if e % 20 == 0:\n",
    "        disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "bins = 64\n",
    "modelb = VARnet(512, len(trainer.types), learnsamples=False, wavelet=\"db8\", infeatures=2)\n",
    "# model = Morphologic(bins, len(trainer.types), 2)\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "epochs = 300\n",
    "loss = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.AdamW(modelb.parameters(), lr=0.0015)\n",
    "\n",
    "losses = []\n",
    "validlosses = []\n",
    "f1s = []\n",
    "modelb.train()\n",
    "iterlim = 50\n",
    "for e in range(epochs):\n",
    "    modelb.train()\n",
    "    epochlosses = []\n",
    "    validations = []\n",
    "    i=0\n",
    "    for data, target in trainer:\n",
    "        if i > iterlim:\n",
    "            break\n",
    "        data = torch.repeat_interleave(data, 2, dim=1)\n",
    "        i += 1\n",
    "        out = modelb(data.cuda())\n",
    "        if torch.sum(torch.isinf(out)) > 0:\n",
    "            print(out)\n",
    "            raise ValueError(\"NaN in output\")\n",
    "        if torch.sum(torch.isinf(data)) > 0:\n",
    "            print(data)\n",
    "            raise ValueError(\"NaN in input\")\n",
    "        if torch.sum(torch.isinf(target)) > 0:\n",
    "            print(target)\n",
    "            raise ValueError(\"NaN in target\")\n",
    "\n",
    "        l = loss(out, target.cuda())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epochlosses.append(l.item())\n",
    "    \n",
    "\n",
    "    # print a confusion matrix\n",
    "    epoch_validlosses = []\n",
    "    modelb.eval()\n",
    "    for data, target in valid:\n",
    "        out = modelb(data.cuda())\n",
    "        epochlosses.append(loss(out, target.cuda()).item())\n",
    "        pred = torch.argmax(out, dim=1).squeeze()\n",
    "        target = torch.argmax(target, dim=1).squeeze()\n",
    "        validations.append((target.cpu(), pred.cpu()))\n",
    "        epoch_validlosses.append((target.cpu(), pred.cpu()))\n",
    "    \n",
    "    validlosses.append(np.mean(epoch_validlosses))\n",
    "    true_y = torch.cat([x[0] for x in validations]).cpu().numpy()\n",
    "    pred_y = torch.cat([x[1] for x in validations]).cpu().numpy()\n",
    "    print(\"N Valids: \", len(true_y))\n",
    "    f1 = f1_score(true_y, pred_y, average=\"macro\")\n",
    "    f1s.append(f1)\n",
    "    cm = confusion_matrix(true_y, pred_y)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=trainer.types)\n",
    "    losses.append(np.mean(epochlosses))\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=losses, line=dict(color=\"blue\"), mode=\"lines\", name=\"train\"))\n",
    "    fig.add_trace(go.Scatter(y=f1s, line=dict(color=\"red\"), mode=\"lines\", name=\"f1\"))\n",
    "    # fig.add_trace(go.Scatter(y=validlosses, line=dict(color=\"orange\"), mode=\"lines\", name=\"valid\"))\n",
    "\n",
    "    if e % 1 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Epoch {e} loss: {np.mean(epochlosses)}\")\n",
    "        print(f\"Epoch {e} valid loss: {np.mean(epoch_validlosses)}\")\n",
    "        print(f\"Epoch {e} f1: {f1}\")\n",
    "        display(fig)\n",
    "        print(confusion_matrix(true_y, pred_y))\n",
    "        # disp.plot()\n",
    "    if e % 20 == 0:\n",
    "        disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "model = Morphologic(64, len(valid.types), 2)\n",
    "model.load_state_dict(torch.load(\"/home/mpaz/neovar/secondary/subclassifier/model/morpho.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "for data, label in valid:\n",
    "    out = model(data.cuda()).detach().cpu()\n",
    "    pred = torch.argmax(out, dim=1).squeeze().cpu()\n",
    "    label = torch.argmax(label, dim=1).squeeze().cpu()\n",
    "    preds.append(pred)\n",
    "    trues.append(label)\n",
    "\n",
    "pred_y = torch.cat(preds).numpy()\n",
    "true_y = torch.cat(trues).numpy()\n",
    "\n",
    "cm = confusion_matrix(true_y, pred_y)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=valid.types)\n",
    "disp.plot(cmap='Blues')\n",
    "disp.im_.colorbar.remove()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=500)\n",
    "rep = classification_report(true_y, pred_y, target_names=valid.types)\n",
    "print(rep)\n",
    "stats = classification_report(true_y, pred_y, target_names=valid.types, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_y, pred_y)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=valid.types)\n",
    "labels = valid.types\n",
    "disp.plot(cmap='Blues')\n",
    "disp.im_.colorbar.remove()\n",
    "plt.show()\n",
    "\n",
    "stats = classification_report(true_y, pred_y, target_names=valid.types, output_dict=True)\n",
    "theta1 = np.linspace(0, 2*np.pi, len(valid.types), endpoint=False) - np.pi/14 + 0.025\n",
    "theta2 = np.linspace(0, 2*np.pi, len(valid.types), endpoint=False) + np.pi/14 + 0.025\n",
    "categories = valid.types\n",
    "\n",
    "ax = plt.subplot(polar=True)\n",
    "ax.bar(theta1, [stats[type_]['precision'] for type_ in categories], width=2*np.pi/len(categories) - np.pi/7 - 0.025, align='center', alpha=1, edgecolor='k', color=\"mediumblue\", linewidth=1, label=\"Precision\")\n",
    "ax.bar(theta2, [stats[type_]['recall'] for type_ in categories], width=2*np.pi/len(categories) - np.pi/7 - 0.025, align='center', alpha=1, edgecolor='k', color=\"cornflowerblue\", linewidth=1, label=\"Recall\")\n",
    "ax.set_xticks(theta1 + np.pi/14, minor=False)\n",
    "ax.set_xticklabels(categories)\n",
    "# make the x tick marks invisible but keep the labels\n",
    "ax.tick_params(axis='x', which='both', length=0)\n",
    "# each pi/7 degrees, draw a dotted spoke\n",
    "for i in range(len(categories)):\n",
    "    ax.plot([theta1[i] - np.pi/14, theta1[i]- np.pi/14], [0, 0.75], color=\"grey\", linestyle=\"--\", label=None)\n",
    "\n",
    "\n",
    "r = (np.linspace(0,2*np.pi, 10000, endpoint=False) + 0.1) % (2*np.pi)\n",
    "get_current_f1 = lambda r: stats[labels[int(np.floor(7*(r - 0.025 + np.pi/7) / (2*np.pi))) % len(labels)]][\"f1-score\"]\n",
    "y = np.vectorize(get_current_f1)(r)\n",
    "ax.plot(r, y, color=\"red\", linewidth=1.25)\n",
    "\n",
    "# set legend, cornflower blue = recall, medium blue = precision in very upper right\n",
    "\n",
    "ax.legend(loc=(0.9, 0.9))\n",
    "\n",
    "ax.set_yticks([0.5, 0.75])\n",
    "ax.set_ylim(0, 0.75)\n",
    "ax.yaxis.grid(True, linestyle='--', color='black')\n",
    "ax.xaxis.grid(False)\n",
    "plt.savefig(\"precision.png\", dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
