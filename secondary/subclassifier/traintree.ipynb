{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataloader import TreeDL\n",
    "from varnet import VARnet\n",
    "from autoencoder import Morphologic\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle as pkl\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, f1_score, precision_score, recall_score, accuracy_score, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import joblib\n",
    "from math import ceil\n",
    "\n",
    "# dtrain = xgb.DMatrix('dtrain.dmatrix')\n",
    "# dtest = xgb.DMatrix('dtest.dmatrix')\n",
    "# dvalid = xgb.DMatrix('dvalid.dmatrix')\n",
    "train = pd.read_parquet('train_featuretbl.parquet')\n",
    "valid = pd.read_parquet('valid_featuretbl.parquet')\n",
    "test = pd.read_parquet('test_featuretbl.parquet')\n",
    "\n",
    "combined = pd.concat([train, valid, test])\n",
    "objs = combined.groupby(\"cluster_id\")\n",
    "types = combined[\"type\"].unique()\n",
    "\n",
    "trainidxs = []\n",
    "valididxs = []\n",
    "testidxs = []\n",
    "\n",
    "for type_ in types:\n",
    "    indices = combined[\"type\"] == type_\n",
    "    groups = combined[indices].groupby(\"cluster_id\")\n",
    "    cids = list(groups.groups)\n",
    "    n = len(cids)\n",
    "    for i in cids[:ceil(0.7*n)]:\n",
    "        trainidxs.extend(list(groups.get_group(i).index))\n",
    "    for i in cids[ceil(0.7*n):ceil(0.85*n)]:\n",
    "        valididxs.extend(list(groups.get_group(i).index))\n",
    "    for i in cids[ceil(0.85*n):]:\n",
    "        testidxs.extend(list(groups.get_group(i).index))\n",
    "\n",
    "train = combined.loc[trainidxs]\n",
    "valid = combined.loc[valididxs].sort_values(\"period_significance\").groupby(\"cluster_id\").first()\n",
    "test = combined.loc[testidxs].sort_values(\"period_significance\").groupby(\"cluster_id\").first()\n",
    "\n",
    "print(train.value_counts(\"type\"))\n",
    "print(valid.value_counts(\"type\"))\n",
    "print(test.value_counts(\"type\"))\n",
    "\n",
    "model = Morphologic(64, 7, features=2)\n",
    "model.load_state_dict(torch.load(\"/home/mpaz/neovar/secondary/subclassifier/model/morpho.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progbar = tqdm.tqdm(total=400) # manually update with number of grid search combinations\n",
    "\n",
    "# silence xgboost\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "def evaluate_params(n_est, max_depth):\n",
    "    tree = xgb.XGBClassifier(n_estimators=n_est, max_depth=max_depth, learning_rate=0.1, n_jobs=20, objective=\"multi:softmax\", num_class=8, verbosity=0)\n",
    "    tree.fit(train.drop(\"type\", axis=1), train[\"type\"].values, eval_set=[(valid.drop(\"type\", axis=1), valid[\"type\"].values)])\n",
    "\n",
    "    # print classification report\n",
    "    pred_y = tree.predict(valid.drop(\"type\", axis=1))\n",
    "    true_y = valid[\"type\"].values\n",
    "    f1 = f1_score(true_y, pred_y, average=\"macro\")\n",
    "    precision = precision_score(true_y, pred_y, average=\"macro\")\n",
    "    recall = recall_score(true_y, pred_y, average=\"macro\")\n",
    "    ascore = accuracy_score(true_y, pred_y)\n",
    "\n",
    "    progbar.update(1)\n",
    "\n",
    "    return (f1, precision, recall, ascore)\n",
    "\n",
    "def evaluate_params_many(pairs):\n",
    "    results = [evaluate_params(*pair) for pair in pairs]\n",
    "    return results\n",
    "    \n",
    "\n",
    "results = np.zeros((10,5))\n",
    "pairs = []\n",
    "for estimator_count in [5, 15, 30, 45, 60, 75, 90, 105, 120, 135]:\n",
    "    for depth in [1, 5, 9, 13, 17, 25]:\n",
    "        pairs.append((estimator_count, depth))\n",
    "\n",
    "pairs = np.random.permutation(pairs).tolist() # randomize the order of the pairs for better parallelization and time estimation\n",
    "chunksize=24\n",
    "\n",
    "res = [evaluate_params(*pair) for pair in pairs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.2, n_jobs=24, verbosity=2, objective=\"multi:softmax\", num_class=7)\n",
    "tree.fit(train.drop(\"type\", axis=1), train[\"type\"].values, eval_set=[(valid.drop(\"type\", axis=1), valid[\"type\"].values)])\n",
    "\n",
    "# print classification report\n",
    "pred_y = tree.predict(test.drop(\"type\", axis=1))\n",
    "true_y = np.array(test[\"type\"].values, dtype=int)\n",
    "a = classification_report(true_y, pred_y)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(true_y, pred_y, normalize='true'), display_labels=[\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"])\n",
    "disp.plot()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print most important features\n",
    "tree.save_model(\"model/best.tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(true_y, pred_y, labels, fname):\n",
    "\n",
    "    cm = confusion_matrix(true_y, pred_y, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "    disp.plot(cmap='Blues')\n",
    "    disp.im_.colorbar.remove()\n",
    "    plt.gcf().set_size_inches(7.5, 7.5)\n",
    "    # set size to 10x10 inches\n",
    "    plt.savefig(fname, dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def precision_recall_graph(true_y, pred_y, labels, fname):\n",
    "    u = np.pi / (2*len(labels))\n",
    "    stats = classification_report(true_y, pred_y, target_names=labels, output_dict=True)\n",
    "    theta1 = np.linspace(0, 2*np.pi, len(labels), endpoint=False) - u\n",
    "    theta2 = np.linspace(0, 2*np.pi, len(labels), endpoint=False) + u\n",
    "\n",
    "    ax = plt.subplot(polar=True)\n",
    "    ax.bar(theta1, [stats[type_]['precision'] for type_ in labels], width=2*u - 0.025, align='center', alpha=1, edgecolor='k', color=\"mediumblue\", linewidth=1)\n",
    "    ax.bar(theta2, [stats[type_]['recall'] for type_ in labels], width=2*u - 0.025, align='center', alpha=1, edgecolor='k', color=\"cornflowerblue\", linewidth=1)\n",
    "    \n",
    "    r = (np.linspace(0,2*np.pi, 10000, endpoint=False) + 0.001) % (2*np.pi)\n",
    "    get_current_f1 = lambda r: stats[labels[int(np.floor(7*(r) / (2*np.pi)))]][\"f1-score\"]\n",
    "    y = np.vectorize(get_current_f1)(r)\n",
    "    ax.plot(r, y, color=\"red\", linewidth=2)\n",
    "\n",
    "    ax.set_xticks(theta1 + u)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend([\"F1 Score\", \"Precision\", \"Recall\"], loc=(0.9, 0.9))\n",
    "    ax.set_yticks([0.5, 0.75, 0.9])\n",
    "    ax.xaxis.grid(True)\n",
    "    plt.gcf().set_size_inches(7.5, 7.5)\n",
    "    plt.savefig(fname, dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "def support_pie_chart(dset, labels, fname):\n",
    "    counts = [dset[\"type\"].value_counts()[i] for i in range(len(labels))]\n",
    "    # shift the labels by one to make the pie chart more readable\n",
    "    counts = counts[::2] + counts[1::2]\n",
    "    labels = labels[::2] + labels[1::2]   \n",
    "    # make a donut chart, with the support of each class\n",
    "    fig, ax = plt.subplots(figsize=(4, 3.15))\n",
    "\n",
    "    data = counts\n",
    "    recipe = [l + \" \" + str(c) for l, c in zip(labels, counts)]\n",
    "\n",
    "    wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=0, colors=[\"mediumblue\", \"cornflowerblue\", \"darkblue\", \"royalblue\", \"navy\", \"blue\", \"dodgerblue\", \"skyblue\"])\n",
    "\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.15\", fc=\"w\", ec=\"k\", lw=0.62)\n",
    "    kw = dict(arrowprops=dict(arrowstyle=\"-\"),\n",
    "            bbox=bbox_props, zorder=0, va=\"center\")\n",
    "\n",
    "    for i, p in enumerate(wedges):\n",
    "        ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "        y = np.sin(np.deg2rad(ang))\n",
    "        x = np.cos(np.deg2rad(ang))\n",
    "        horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "        connectionstyle = f\"angle,angleA=0,angleB={ang}\"\n",
    "        kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "        ax.annotate(recipe[i], xy=(x, y), xytext=(1.5*np.sign(x), 1.8*y),\n",
    "                    horizontalalignment=horizontalalignment, **kw)\n",
    "    \n",
    "    plt.gcf().set_size_inches(5, 3.75)\n",
    "    plt.savefig(fname, dpi=400)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_y, pred_y, normalize='true') \n",
    "labels = [\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"]\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "disp.plot(cmap='Blues')\n",
    "disp.im_.colorbar.remove()\n",
    "plt.show()\n",
    "\n",
    "stats = classification_report(true_y, pred_y, target_names=labels, output_dict=True)\n",
    "theta1 = np.linspace(0, 2*np.pi, len(labels), endpoint=False) - np.pi/14 + 0.025\n",
    "theta2 = np.linspace(0, 2*np.pi, len(labels), endpoint=False) + np.pi/14 + 0.025\n",
    "categories = labels\n",
    "\n",
    "ax = plt.subplot(polar=True)\n",
    "ax.bar(theta1, [stats[type_]['precision'] for type_ in categories], width=2*np.pi/len(categories) - np.pi/7 - 0.025, align='center', alpha=1, edgecolor='k', color=\"mediumblue\", linewidth=1, label=\"Precision\")\n",
    "ax.bar(theta2, [stats[type_]['recall'] for type_ in categories], width=2*np.pi/len(categories) - np.pi/7 - 0.025, align='center', alpha=1, edgecolor='k', color=\"cornflowerblue\", linewidth=1, label=\"Recall\")\n",
    "ax.set_xticks(theta1 + np.pi/14, minor=False)\n",
    "ax.set_xticklabels(categories)\n",
    "# make the x tick marks invisible but keep the labels\n",
    "ax.tick_params(axis='x', which='both', length=0)\n",
    "# each pi/7 degrees, draw a dotted spoke\n",
    "for i in range(len(categories)):\n",
    "    ax.plot([theta1[i] - np.pi/14, theta1[i]- np.pi/14], [0, 1], color=\"grey\", linestyle=\"--\", label=None)\n",
    "\n",
    "\n",
    "r = (np.linspace(0,2*np.pi, 10000, endpoint=False) + 0.1) % (2*np.pi)\n",
    "get_current_f1 = lambda r: stats[labels[int(np.floor(7*(r - 0.025 + np.pi/7) / (2*np.pi))) % len(labels)]][\"f1-score\"]\n",
    "y = np.vectorize(get_current_f1)(r)\n",
    "ax.plot(r, y, color=\"red\", linewidth=1.25)\n",
    "\n",
    "# set legend, cornflower blue = recall, medium blue = precision in very upper right\n",
    "\n",
    "ax.legend(loc=(0.9, 0.9))\n",
    "\n",
    "ax.set_yticks([0.5, 0.9, 1])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.yaxis.grid(True, linestyle='--', color='black')\n",
    "ax.xaxis.grid(False)\n",
    "plt.savefig(\"precision.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = tree.get_booster()\n",
    "p = bst.inplace_predict(test.drop(\"type\", axis=1).values, predict_type=\"margin\")\n",
    "pred = np.argmax(p, axis=1)\n",
    "prob = np.max(np.exp(p) / np.sum(np.exp(p), axis=1).reshape(-1,1), axis=1)\n",
    "true_y = np.array(test[\"type\"].values, dtype=int)\n",
    "a = classification_report(true_y, pred_y)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(true_y, pred), display_labels=[\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"])\n",
    "disp.plot()\n",
    "print(a)\n",
    "\n",
    "confusion_matrix_plot(true_y, pred, [\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"], \"confusion_matrix.png\")\n",
    "precision_recall_graph(true_y, pred, [\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"], \"precision_recall.png\")\n",
    "support_pie_chart(test.groupby(\"cluster_id\").first(), [\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"], \"test_support.png\")\n",
    "support_pie_chart(train.groupby(\"cluster_id\").first(), [\"ea\", \"ew\", \"lpv\", \"rot\", \"rr\", \"cep\", \"yso\"], \"train_support.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
