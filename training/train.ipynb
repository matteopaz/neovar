{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import *\n",
    "from datagen.genset import GenSet\n",
    "from training_helpers import *\n",
    "\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m GenSet()\n\u001b[0;32m----> 2\u001b[0m valid \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./valid/valid_data.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "train = GenSet()\n",
    "valid = pickle.load(\"./valid/valid_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn1.weight 624\n",
      "cnn1.bias 16\n",
      "cnn2.weight 4224\n",
      "cnn2.bias 24\n",
      "cnn3.weight 864\n",
      "cnn3.bias 4\n",
      "cnn4.weight 3168\n",
      "cnn4.bias 32\n",
      "cnn5.weight 3584\n",
      "cnn5.bias 16\n",
      "cnn6.weight 320\n",
      "cnn6.bias 4\n",
      "cnnafter1.weight 672\n",
      "cnnafter1.bias 24\n",
      "cnnafter2.weight 4896\n",
      "cnnafter2.bias 12\n",
      "cnnafter3.weight 132\n",
      "cnnafter3.bias 1\n",
      "layerone.weight 131072\n",
      "layerone.bias 256\n",
      "layertwo.weight 32768\n",
      "layertwo.bias 128\n",
      "layerthree.weight 512\n",
      "layerthree.bias 4\n",
      "fdft.freqs 512\n",
      "norm.weight 128\n",
      "norm.bias 128\n",
      "bnorm.weight 3\n",
      "bnorm.bias 3\n",
      "184131\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(wavelet=\"bior2.2\", samples=512, out=4, learnsamples=True)\n",
    "model = WCNFourierModel(**kwargs).to(device)\n",
    "model_pars = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_pars])\n",
    "\n",
    "for p in model.named_parameters():\n",
    "    print(p[0], np.prod(p[1].size()))\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS_PER_EPOCH = 100\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=0.000085, weight_decay=10**-5.5, amsgrad=True)\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "epoch_training_losses = []\n",
    "epoch_validation = []\n",
    "\n",
    "for batch, label in train:\n",
    "    epoch_training_loss = []\n",
    "    optim.zero_grad()\n",
    "    out = model(batch)\n",
    "    loss = loss(out, label)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    epoch_training_loss.append(loss.item())\n",
    "\n",
    "    if len(epoch_training_losses) % ITERATIONS_PER_EPOCH == 0:\n",
    "        model.eval()\n",
    "        data, label, types = valid\n",
    "        out = model(data)\n",
    "\n",
    "        true_y = torch.argmax(label, dim=1).flatten().cpu().numpy()\n",
    "        pred_y = torch.argmax(out, dim=1).flatten().cpu().numpy()\n",
    "\n",
    "        epoch_training_losses.append(np.mean(epoch_training_loss))\n",
    "        epoch_validation.append((types, pred_y))\n",
    "\n",
    "        training_plot(epoch_training_losses, epoch_validation)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
